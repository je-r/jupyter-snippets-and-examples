{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xgboost-jupyter-example-001.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJQd-lY4CvOx"
      },
      "source": [
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import dump_svmlight_file\n",
        "### commented out because of warning:\n",
        "#from sklearn.externals import joblib\n",
        "### above replaced with this:\n",
        "import joblib\n",
        "from sklearn.metrics import precision_score\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0FvTzvTD7J4"
      },
      "source": [
        "# First you load the dataset from sklearn, where X will be the data, y â€“ the class labels:\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUzmx4oEGESP"
      },
      "source": [
        "# split the data into train and test sets with 80-20% split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dHCJ5BdGsbs"
      },
      "source": [
        "# use DMatrix for xgboost, create the Xgboost specific DMatrix data\n",
        "# format from the numpy array. Xgboost can work with numpy arrays directly, load data from svmlight files and other formats\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_9E7D4wHOx6",
        "outputId": "3d48d60c-95b1-4f8e-93fa-1eefa6038213"
      },
      "source": [
        "# use svmlight file for xgboost, If you want to use svmlight for less memory \n",
        "# consumption, first dump the numpy array into svmlight format and then just pass the filename to DMatrix:\n",
        "dump_svmlight_file(X_train, y_train, 'dtrain.svm', zero_based=True)\n",
        "dump_svmlight_file(X_test, y_test, 'dtest.svm', zero_based=True)\n",
        "dtrain_svm = xgb.DMatrix('dtrain.svm')\n",
        "dtest_svm = xgb.DMatrix('dtest.svm')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18:35:37] 120x4 matrix with 480 entries loaded from dtrain.svm\n",
            "[18:35:37] 30x4 matrix with 120 entries loaded from dtest.svm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDwmjtGdH2ps"
      },
      "source": [
        "# set xgboost params\n",
        "param = {\n",
        "    'max_depth': 3,  # the maximum depth of each tree\n",
        "    'eta': 0.3,  # the training step for each iteration\n",
        "    'silent': 1,  # logging mode - quiet\n",
        "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
        "    'num_class': 3}  # the number of classes that exist in this datset\n",
        "num_round = 20  # the number of training iterations"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxLPZjEmILZM"
      },
      "source": [
        "#------------- numpy array ------------------\n",
        "# training and testing - numpy matrices\n",
        "bst = xgb.train(param, dtrain, num_round)\n",
        "preds = bst.predict(dtest)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8eD2EboIXi6",
        "outputId": "63dd02c3-02d6-43e2-f063-2187ac1826f2"
      },
      "source": [
        "# extracting most confident predictions\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "print(\"Numpy array precision:\", precision_score(y_test, best_preds, average='macro'))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numpy array precision: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f90Ynn1tIvvq"
      },
      "source": [
        "# ------------- svm file ---------------------\n",
        "# training and testing - svm file\n",
        "bst_svm = xgb.train(param, dtrain_svm, num_round)\n",
        "preds = bst.predict(dtest_svm)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYEkLSLhI2oo",
        "outputId": "4d07a011-f0b3-4391-dc9a-1098d328dca1"
      },
      "source": [
        "# extracting most confident predictions\n",
        "best_preds_svm = [np.argmax(line) for line in preds]\n",
        "print(\"Svm file precision:\",precision_score(y_test, best_preds_svm, average='macro'))\n",
        "# --------------------------------------------"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Svm file precision: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29lFsTJ_JqoW"
      },
      "source": [
        "# dump the models\n",
        "bst.dump_model('dump.raw.txt')\n",
        "bst_svm.dump_model('dump_svm.raw.txt')"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNowhNq1LnUa",
        "outputId": "a7fb0e45-a97b-4493-c4cc-efb9cc95358a"
      },
      "source": [
        "# save the models for later\n",
        "joblib.dump(bst, 'bst_model.pkl', compress=True)\n",
        "joblib.dump(bst_svm, 'bst_svm_model.pkl', compress=True)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bst_svm_model.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    }
  ]
}